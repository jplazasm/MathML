{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5689689",
   "metadata": {},
   "source": [
    "# Simple binary classification (Sonar, Mines vs. Rocks)\n",
    "\n",
    "In this notebook we will fit the ML algorithms: Linear Regression, Logistic Regression, SVM, kNN and Decision trees, to a dataset containing stone and mine signals obtained from a variety of different aspect angles, with the aim of predicting whether an object is either a mine or a rock given the strength of sonar returns at different angles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1e116",
   "metadata": {},
   "source": [
    "Let's read the data. The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine, we will asign the boolean 0 for the class \"R\", and the boolean 1 for the class \"M\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e52922",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "data = DataFrame(CSV.File(\"data/sonar.csv\", header = 0) )\n",
    "rename!(data, :Column61 => :class)\n",
    "data.class = Bool.(replace(data.class, \"R\" => 0, \"M\" => 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb40ef3",
   "metadata": {},
   "source": [
    "Let's check if the classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49ae8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Bool, Int64} with 2 entries:\n",
       "  0 => 97\n",
       "  1 => 111"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using StatsBase\n",
    "countmap(data.class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737aa70",
   "metadata": {},
   "source": [
    "As we can see, we have a problem of imbalanced classes. Since we don’t have a ton of data to work with, the Random Over-Sampling Technique can be a good choice to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6adf8f35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Bool, Int64} with 2 entries:\n",
       "  0 => 111\n",
       "  1 => 111"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDataPattern\n",
    "\n",
    "X = Matrix(data[:, 1:60])';\n",
    "y = data.class;\n",
    "X_bal, y_bal = oversample((X, y));\n",
    "\n",
    "\n",
    "data_bal = DataFrame(Matrix(X_bal'));\n",
    "data_bal.class = y_bal;\n",
    "\n",
    "countmap(data_bal.class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b1c69",
   "metadata": {},
   "source": [
    "We would rather partition the balanced data set into two disjoint subsets using random assignment. We can do this by combining splitobs() with shuffleobs()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22dfe819",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDataUtils \n",
    "train, test = splitobs(shuffleobs(data_bal), at = 0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e185082a",
   "metadata": {},
   "source": [
    "Now, our data train has 155 elements (70% of total data), the data test has 67 elements (30% of total data), and its classes are distributed as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15a20a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Bool, Int64} with 2 entries:\n",
       "  0 => 76\n",
       "  1 => 79"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countmap(train.class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c75a6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Bool, Int64} with 2 entries:\n",
       "  0 => 35\n",
       "  1 => 32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countmap(test.class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be6d13",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "We will use the Confusion Matrix as a performance function for the problem. The Confusion matrix is a table with two rows and two columns that reports the number of true positives, false negatives, false positives, and true negatives, and is often used to evaluate the performance of a classification model. \n",
    "\n",
    "Different metrics are derived from this matrix, some of them are precision, accuracy, sensitivity and specificity. The convenience of using a metric as a measure of the estimator depends on each particular case and, specifically, on the \"cost\" associated with each classification error of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fef78537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conf_matrix_metrics (generic function with 1 method)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using EvalMetrics\n",
    "\n",
    "function conf_matrix_metrics(test, pred)\n",
    "    conf_matrix = counts(test, pred)\n",
    "    precision = EvalMetrics.precision(test, pred)\n",
    "    accuracy = EvalMetrics.accuracy(test, pred)\n",
    "    sensitivity = EvalMetrics.sensitivity(test, pred)\n",
    "    specificity = EvalMetrics.specificity(test, pred)\n",
    "    \n",
    "    println(\"The Confusion Matrix of this model is \", conf_matrix)\n",
    "    println(\"The precision of this model is \", precision)\n",
    "    println(\"The accuracy of this model is \", accuracy)\n",
    "    println(\"The sensitivity of this model is \", sensitivity)\n",
    "    println(\"The specificity of this model is \", specificity)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254fc46",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Let's train Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6da16489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "class ~ 1 + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 + x26 + x27 + x28 + x29 + x30 + x31 + x32 + x33 + x34 + x35 + x36 + x37 + x38 + x39 + x40 + x41 + x42 + x43 + x44 + x45 + x46 + x47 + x48 + x49 + x50 + x51 + x52 + x53 + x54 + x55 + x56 + x57 + x58 + x59 + x60\n",
       "\n",
       "Coefficients:\n",
       "─────────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error      t  Pr(>|t|)    Lower 95%   Upper 95%\n",
       "─────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  -0.256354     0.358865  -0.71    0.4768   -0.968889    0.456181\n",
       "x1            2.71934      2.57833    1.05    0.2943   -2.39999     7.83867\n",
       "x2            2.14467      2.97614    0.72    0.4729   -3.76452     8.05387\n",
       "x3           -5.56708      2.80484   -1.98    0.0501  -11.1362      0.0019846\n",
       "x4            3.23753      2.00744    1.61    0.1101   -0.748286    7.22335\n",
       "x5           -0.0816242    1.46209   -0.06    0.9556   -2.98463     2.82138\n",
       "x6            0.84246      1.34753    0.63    0.5334   -1.83309     3.51801\n",
       "x7           -0.976386     1.44126   -0.68    0.4998   -3.83803     1.88526\n",
       "x8           -1.35616      1.08175   -1.25    0.2131   -3.50401     0.791679\n",
       "x9            0.637217     0.973143   0.65    0.5142   -1.29498     2.56942\n",
       "x10          -0.0198738    0.968973  -0.02    0.9837   -1.94379     1.90404\n",
       "x11           0.199881     1.10683    0.18    0.8571   -1.99776     2.39752\n",
       "x12           1.04389      0.86243    1.21    0.2292   -0.668481    2.75627\n",
       "x13           0.027675     0.876323   0.03    0.9749   -1.71228     1.76763\n",
       "x14           0.169687     0.822778   0.21    0.8371   -1.46396     1.80333\n",
       "x15          -0.14369      0.863456  -0.17    0.8682   -1.8581      1.57072\n",
       "x16           0.222852     0.83024    0.27    0.7890   -1.42561     1.87131\n",
       "x17          -0.618724     0.864873  -0.72    0.4761   -2.33595     1.0985\n",
       "x18           0.319261     0.833117   0.38    0.7024   -1.33491     1.97343\n",
       "x19           0.0113948    0.699439   0.02    0.9870   -1.37736     1.40015\n",
       "x20           0.0779306    0.802252   0.10    0.9228   -1.51496     1.67082\n",
       "x21          -0.380425     0.759535  -0.50    0.6176   -1.8885      1.12765\n",
       "x22           0.884881     0.740006   1.20    0.2348   -0.584417    2.35418\n",
       "x23          -0.918826     0.748169  -1.23    0.2225   -2.40433     0.566682\n",
       "x24           1.45095      0.752883   1.93    0.0570   -0.0439197   2.94581\n",
       "x25          -1.09734      0.698297  -1.57    0.1194   -2.48383     0.289142\n",
       "x26           0.472104     0.765136   0.62    0.5387   -1.04709     1.9913\n",
       "x27           0.0130984    0.774947   0.02    0.9866   -1.52558     1.55177\n",
       "x28          -0.0307302    0.706184  -0.04    0.9654   -1.43287     1.37141\n",
       "x29          -0.279502     0.670503  -0.42    0.6777   -1.6108      1.0518\n",
       "x30           1.36315      0.751644   1.81    0.0729   -0.129254    2.85556\n",
       "x31          -2.10306      0.739907  -2.84    0.0055   -3.57216    -0.633953\n",
       "x32           1.13226      0.703234   1.61    0.1107   -0.264029    2.52855\n",
       "x33           0.0500437    0.693085   0.07    0.9426   -1.32609     1.42618\n",
       "x34          -0.595144     0.680041  -0.88    0.3837   -1.94538     0.755093\n",
       "x35           0.673504     0.675237   1.00    0.3211   -0.667195    2.0142\n",
       "x36          -0.6937       0.71322   -0.97    0.3332   -2.10982     0.722416\n",
       "x37          -0.300182     0.707608  -0.42    0.6724   -1.70515     1.10479\n",
       "x38           0.410771     0.825148   0.50    0.6198   -1.22758     2.04912\n",
       "x39           0.517742     0.76014    0.68    0.4975   -0.991533    2.02702\n",
       "x40          -0.90366      0.776422  -1.16    0.2474   -2.44526     0.637943\n",
       "x41           0.580495     0.759888   0.76    0.4468   -0.928281    2.08927\n",
       "x42          -0.0630697    0.732616  -0.09    0.9316   -1.5177      1.39156\n",
       "x43           0.230567     0.835752   0.28    0.7832   -1.42884     1.88997\n",
       "x44          -0.27911      1.00696   -0.28    0.7823   -2.27845     1.72023\n",
       "x45           0.457463     1.0224     0.45    0.6556   -1.57254     2.48747\n",
       "x46          -0.571216     1.2001    -0.48    0.6352   -2.95404     1.81161\n",
       "x47           0.961246     1.64813    0.58    0.5611   -2.31115     4.23365\n",
       "x48           0.825524     2.26965    0.36    0.7169   -3.68092     5.33197\n",
       "x49           2.96053      3.24517    0.91    0.3640   -3.48282     9.40388\n",
       "x50          -7.30999      5.5669    -1.31    0.1923  -18.3632      3.74321\n",
       "x51          -0.659751     5.57187   -0.12    0.9060  -11.7228     10.4033\n",
       "x52           4.046        6.13648    0.66    0.5113   -8.13813    16.2301\n",
       "x53          -0.248728     7.82347   -0.03    0.9747  -15.7824     15.2849\n",
       "x54           8.58184      6.58727    1.30    0.1958   -4.49735    21.661\n",
       "x55          -9.6635       7.62629   -1.27    0.2082  -24.8057      5.47867\n",
       "x56          -6.64017     10.8451    -0.61    0.5418  -28.1733     14.893\n",
       "x57           1.68802      9.6482     0.17    0.8615  -17.4687     20.8447\n",
       "x58           7.62682      9.74937    0.78    0.4360  -11.7308     26.9844\n",
       "x59           8.3623      11.7949     0.71    0.4801  -15.0568     31.7814\n",
       "x60          -8.47174     11.8667    -0.71    0.4771  -32.0334     15.0899\n",
       "─────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using GLM\n",
    "fm = Term(:class) ~ sum(term.(names(train[:,1:60])))\n",
    "linearRegressor = lm(fm, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d551834",
   "metadata": {},
   "source": [
    "Take a look at the decision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b121e80e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34028862845542024, -0.09225465426152925, 0.11111374600980137, 0.3614691190514965, 0.49586143623864054, -0.5002456603018126, -0.16833342051042316, 0.0791976241575987, 0.026722537855394343, 0.753884284210186, 0.29105572879212066, 0.6970420281554053, 0.2685946142612683, 0.7081114475226417, 0.7720175195009962, 1.310273348866756, 0.1820959614243846, 0.10243076304886312, 0.6170823980654903, 0.25431176798835226, -0.20454965634635375, 0.543804988942905, 0.22177147442544268, 0.5481446059007851, 0.22069792773862779, 0.3073836358865745, 0.19198859380004318, 0.8254855722954937, 0.09999938548382084, -0.00678567075794833, 0.3257110633909801, 0.7143266084008066, 0.347947598539777, 0.5965694104493858, 0.5639554063679135, 1.2735633572926235, 0.5415262741680118, 0.9389182076348137, 0.8419093186006387, 0.3778607652930825, 0.734411503202917, 0.434839161102965, 0.018017066473264676, 0.8340076301654891, 0.836322623185664, 0.03464203446809984, 1.5611457751268223, 0.2163872255215501, 0.8475343922489843, 0.31117498269708704, 0.1858463696302216, 0.8305328986318689, 0.45182456350258793, 0.15062534676128203, 0.044025605463306645, 1.120690820678249, -0.04913748588348851, 1.0465038639481565, 0.5421517014100689, 0.0775970446684292, 0.44265203483573856, 0.48414018589234764, 0.508882659822006, 0.11111374600980137, 0.8362538854113054, 0.44425329932927216, 1.2309319810736554]\n"
     ]
    }
   ],
   "source": [
    "LinR_pred = Float64.(GLM.predict(linearRegressor,test))\n",
    "println(LinR_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b5713",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Convert the decision values to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "633b2b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_act  = Bool[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "label_pred = Bool[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "y_test = Bool.(test.class)\n",
    "y_LinR_pred = Bool.([if x < 0.5 0 else 1 end for x in LinR_pred]);\n",
    "\n",
    "println(\"label_act  = \", y_test)\n",
    "println(\"label_pred = \", y_LinR_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4f343",
   "metadata": {},
   "source": [
    "Now let's look at the model's confusion matrix along with the previously mentioned metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "472e741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix of this model is [32 3; 7 25]\n",
      "The precision of this model is 0.8928571428571429\n",
      "The accuracy of this model is 0.8507462686567164\n",
      "The sensitivity of this model is 0.78125\n",
      "The specificity of this model is 0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_metrics(y_test, y_LinR_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f482a2",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Let's train Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec72d5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Vector{Float64}, Binomial{Float64}, ProbitLink}, GLM.DensePredChol{Float64, LinearAlgebra.Cholesky{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
       "\n",
       "class ~ 1 + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 + x26 + x27 + x28 + x29 + x30 + x31 + x32 + x33 + x34 + x35 + x36 + x37 + x38 + x39 + x40 + x41 + x42 + x43 + x44 + x45 + x46 + x47 + x48 + x49 + x50 + x51 + x52 + x53 + x54 + x55 + x56 + x57 + x58 + x59 + x60\n",
       "\n",
       "Coefficients:\n",
       "──────────────────────────────────────────────────────────────────────────────────────────\n",
       "                   Coef.      Std. Error      z  Pr(>|z|)        Lower 95%       Upper 95%\n",
       "──────────────────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)    -81.2141    81116.7        -0.00    0.9992  -159067.0             1.58905e5\n",
       "x1             267.682         5.36437e5   0.00    0.9996       -1.05113e6       1.05167e6\n",
       "x2             -79.7684        6.0534e5   -0.00    0.9999       -1.18652e6       1.18637e6\n",
       "x3            -239.085         3.52901e5  -0.00    0.9995       -6.91913e5       6.91434e5\n",
       "x4             228.239         1.81419e5   0.00    0.9990       -3.55347e5       3.55804e5\n",
       "x5             -52.377     73684.4        -0.00    0.9994       -1.44471e5       1.44366e5\n",
       "x6              95.7457        1.20164e5   0.00    0.9994       -2.35421e5  235612.0\n",
       "x7             -54.6914        1.61486e5  -0.00    0.9997       -3.16561e5       3.16451e5\n",
       "x8            -142.218     66224.3        -0.00    0.9983       -1.2994e5        1.29655e5\n",
       "x9              54.4526    38751.7         0.00    0.9989   -75897.5         76006.4\n",
       "x10            -26.3609        1.20172e5  -0.00    0.9998       -2.3556e5        2.35507e5\n",
       "x11             74.0909        1.12614e5   0.00    0.9995       -2.20645e5       2.20794e5\n",
       "x12             40.648    112933.0         0.00    0.9997  -221304.0             2.21385e5\n",
       "x13            -12.019         1.72594e5  -0.00    0.9999       -3.38291e5       3.38267e5\n",
       "x14            -20.3285    76666.6        -0.00    0.9998  -150284.0             1.50243e5\n",
       "x15             28.3253    93067.2         0.00    0.9998  -182380.0             1.82437e5\n",
       "x16             12.0108    76044.9         0.00    0.9999       -1.49033e5       1.49057e5\n",
       "x17            -91.9768        1.40587e5  -0.00    0.9995       -2.75637e5       2.75453e5\n",
       "x18             44.0718        1.30851e5   0.00    0.9997       -2.56419e5       2.56507e5\n",
       "x19             -1.08247   54194.9        -0.00    1.0000       -1.06221e5       1.06219e5\n",
       "x20             20.3436        1.75031e5   0.00    0.9999       -3.43033e5       3.43074e5\n",
       "x21            -59.8275        1.7943e5   -0.00    0.9997       -3.51736e5       3.51617e5\n",
       "x22            137.246     90914.2         0.00    0.9988       -1.78051e5       1.78326e5\n",
       "x23            -52.2737        1.1726e5   -0.00    0.9996       -2.29878e5       2.29774e5\n",
       "x24             28.7929    65613.7         0.00    0.9996       -1.28572e5       1.28629e5\n",
       "x25              6.35175   70860.5         0.00    0.9999       -1.38878e5       1.3889e5\n",
       "x26            -35.9419    73216.2        -0.00    0.9996  -143537.0             1.43465e5\n",
       "x27             22.7446    57748.1         0.00    0.9997       -1.13161e5  113207.0\n",
       "x28            -17.5646        1.17697e5  -0.00    0.9999       -2.30699e5       2.30663e5\n",
       "x29             16.3004        1.07578e5   0.00    0.9999       -2.10833e5       2.10866e5\n",
       "x30             74.5263        1.05589e5   0.00    0.9994       -2.06875e5       2.07024e5\n",
       "x31           -105.355     74263.6        -0.00    0.9989       -1.45659e5       1.45449e5\n",
       "x32             59.9391    46581.6         0.00    0.9990   -91238.2         91358.1\n",
       "x33             11.5934    89498.7         0.00    0.9999       -1.75403e5       1.75426e5\n",
       "x34            -75.0906        1.08589e5  -0.00    0.9994       -2.12906e5       2.12756e5\n",
       "x35             49.1595    67070.3         0.00    0.9994       -1.31406e5       1.31505e5\n",
       "x36            -21.3222    77626.1        -0.00    0.9998       -1.52166e5       1.52123e5\n",
       "x37            -56.6462    76322.6        -0.00    0.9994       -1.49646e5       1.49533e5\n",
       "x38             34.8214    36432.1         0.00    0.9992   -71370.8         71440.5\n",
       "x39             55.1065    73457.6         0.00    0.9994       -1.43919e5       1.44029e5\n",
       "x40            -57.5091    40704.5        -0.00    0.9989   -79836.9         79721.9\n",
       "x41            -34.3465        1.225e5    -0.00    0.9998       -2.40129e5       2.4006e5\n",
       "x42            137.732         2.40965e5   0.00    0.9995       -4.72146e5  472421.0\n",
       "x43              9.54559       1.97373e5   0.00    1.0000       -3.86834e5       3.86853e5\n",
       "x44           -106.909    121949.0        -0.00    0.9993       -2.39123e5       2.38909e5\n",
       "x45             36.3863    50811.2         0.00    0.9994   -99551.7         99624.5\n",
       "x46            168.773         1.28021e5   0.00    0.9989       -2.50747e5       2.51085e5\n",
       "x47           -266.429         1.27798e5  -0.00    0.9983       -2.50745e5       2.50212e5\n",
       "x48            169.286         2.72829e5   0.00    0.9995  -534565.0             5.34904e5\n",
       "x49            219.308         4.96887e5   0.00    0.9996       -9.73661e5       9.74099e5\n",
       "x50           -995.911         8.59447e5  -0.00    0.9991       -1.68548e6       1.68349e6\n",
       "x51            863.486         1.06366e6   0.00    0.9994       -2.08386e6       2.08559e6\n",
       "x52            831.167         7.55103e5   0.00    0.9991       -1.47914e6       1.48081e6\n",
       "x53            544.702         3.28084e5   0.00    0.9987       -6.42488e5       6.43578e5\n",
       "x54            179.779         2.02576e6   0.00    0.9999       -3.97025e6       3.97061e6\n",
       "x55            454.984         7.92441e5   0.00    0.9995       -1.5527e6        1.55361e6\n",
       "x56           -563.484         1.99569e6  -0.00    0.9998       -3.91204e6       3.91092e6\n",
       "x57            147.477         1.03575e6   0.00    0.9999       -2.02988e6       2.03018e6\n",
       "x58             90.3605        2.03558e6   0.00    1.0000       -3.98958e6       3.98976e6\n",
       "x59            950.161    522482.0         0.00    0.9985       -1.0231e6        1.025e6\n",
       "x60          -1025.79          6.17792e5  -0.00    0.9987       -1.21188e6       1.20982e6\n",
       "──────────────────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using GLM\n",
    "fm = Term(:class) ~ sum(term.(names(train[:,1:60])))\n",
    "logitRegressor = glm(fm, train, Binomial(), ProbitLink())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbf6b5",
   "metadata": {},
   "source": [
    "Take a look at the decision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd64f3cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 7.619292719840532e-38, 1.6146773455955954e-21, 9.022785414499048e-290, 1.3958802761706985e-10, 0.0, 0.0, 2.504665041316085e-91, 0.0, 1.0, 4.9128041627586666e-182, 1.0, 1.779626452770876e-78, 1.5148091663210064e-9, 1.0, 1.0, 5.2682718445099516e-126, 0.0, 1.6310504520692574e-44, 2.1187835536423834e-141, 0.0, 0.0, 4.4924624946141885e-12, 1.0, 1.0, 1.0, 3.829418860799304e-68, 1.0, 2.6020983159332347e-19, 0.0, 2.920432075600862e-9, 1.0, 0.9999992293806472, 7.332103004666202e-14, 7.475695087271257e-20, 1.0, 0.0, 1.0, 1.0, 1.4468857609932417e-108, 0.9999137952339894, 1.0, 8.03283854e-316, 1.0, 1.0, 2.964926973219872e-31, 1.0, 2.0516710308879897e-128, 1.0, 1.3060064549100277e-243, 0.0, 1.0, 9.009376017075312e-126, 7.073579727149234e-24, 1.0, 1.0, 0.0, 1.0, 1.0, 2.1369180941509546e-246, 1.7764860756122216e-256, 1.0, 1.0, 1.6146773455955954e-21, 1.0, 1.623271112125105e-9, 1.0]\n"
     ]
    }
   ],
   "source": [
    "LogR_pred = Float64.(GLM.predict(logitRegressor,test))\n",
    "println(LogR_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab71fdfa",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Convert probability score to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2706f59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_act  = Bool[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "label_pred = Bool[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "y_test = Bool.(test.class)\n",
    "y_LogR_pred = Bool.([if x < 0.5 0 else 1 end for x in LogR_pred]);\n",
    "\n",
    "println(\"label_act  = \", y_test)\n",
    "println(\"label_pred = \", y_LogR_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce6737d",
   "metadata": {},
   "source": [
    "Now let's look at the model's confusion matrix along with the previously mentioned metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "373f31b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix of this model is [30 5; 8 24]\n",
      "The precision of this model is 0.8275862068965517\n",
      "The accuracy of this model is 0.8059701492537313\n",
      "The sensitivity of this model is 0.75\n",
      "The specificity of this model is 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_metrics(y_test, y_LogR_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34818b4",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "Let's train SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59ef1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LIBSVM\n",
    "\n",
    "X_train = Matrix(train[:, 1:60])'\n",
    "X_test = Matrix(test[:, 1:60])'\n",
    "y_train = Bool.(train.class)\n",
    "y_test = Bool.(test.class)\n",
    "\n",
    "model = svmtrain(X_train, y_train);\n",
    "\n",
    "y_SVM_pred, SVM_pred = svmpredict(model, X_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e6777",
   "metadata": {},
   "source": [
    "Take a look at the decision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88ab8bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×67 Matrix{Float64}:\n",
       " 0.280507  0.0640837  -0.0935976  -0.430027  …  1.14289  0.258246  1.05152\n",
       " 0.0       0.0         0.0         0.0          0.0      0.0       0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297ac37",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Convert the decision values to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbf34948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_act  = Bool[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "label_pred = Bool[1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "println(\"label_act  = \", y_test)\n",
    "println(\"label_pred = \", y_SVM_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff3514a",
   "metadata": {},
   "source": [
    "Now let's look at the model's confusion matrix along with the previously mentioned metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce0b0c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix of this model is [15 20; 5 27]\n",
      "The precision of this model is 0.574468085106383\n",
      "The accuracy of this model is 0.6268656716417911\n",
      "The sensitivity of this model is 0.84375\n",
      "The specificity of this model is 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_metrics(y_test, y_SVM_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17095740",
   "metadata": {},
   "source": [
    "# k Nearest Neighbors\n",
    "Let's train k Nearest Neighbors model. We will take the parameter as $k=3$, the reader can verify that with this value better values are obtained in the mentioned metrics, than with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3feab33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NearestNeighbors\n",
    "\n",
    "X_train = Matrix(train[:, 1:60])'\n",
    "X_test = Matrix(test[:, 1:60])'\n",
    "y_train = Bool.(train.class)\n",
    "y_test = Bool.(test.class)\n",
    "\n",
    "k = 3\n",
    "\n",
    "kdtree_train = KDTree(X_train)\n",
    "idxs, dists = knn(kdtree_train, X_test, k, true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de0e22",
   "metadata": {},
   "source": [
    "Take a look at the decision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2944f951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×67 adjoint(::BitMatrix) with eltype Bool:\n",
       " 1  0  0  1  0  0  0  0  0  1  0  1  1  …  0  0  1  1  1  1  1  1  0  1  0  1\n",
       " 1  0  0  1  1  0  0  0  0  1  0  1  0     0  0  1  1  0  1  1  1  0  1  0  1\n",
       " 0  0  0  1  1  0  0  0  0  0  0  1  1     0  0  1  1  0  1  1  1  0  1  0  1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbors_labels = y_train[hcat(idxs...)'];\n",
    "nbors_labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cd469",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Convert the decision values to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c05b582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_act  = Bool[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "label_pred = Bool[1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "y_kNN_pred = [argmax(countmap(nbors_labels[i, :]))  for i in 1:size(nbors_labels)[1]];\n",
    "println(\"label_act  = \", y_test)\n",
    "println(\"label_pred = \", y_kNN_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e9b9f",
   "metadata": {},
   "source": [
    "Now let's look at the model's confusion matrix along with the previously mentioned metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ced08a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix of this model is [30 5; 4 28]\n",
      "The precision of this model is 0.8484848484848485\n",
      "The accuracy of this model is 0.8656716417910447\n",
      "The sensitivity of this model is 0.875\n",
      "The specificity of this model is 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_metrics(y_test, y_kNN_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c74498",
   "metadata": {},
   "source": [
    "#  Decision trees\n",
    "Let's train decision trees model. We will take the parameter as max_depth$=7$, the reader can verify that with this value better values are obtained in the mentioned metrics, than with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38360779",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DecisionTree\n",
    "\n",
    "features = Matrix(train[:, 1:60])\n",
    "labels = train.class\n",
    "\n",
    "features = float.(features)\n",
    "labels   = Bool.(labels);\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=7)\n",
    "DecisionTree.fit!(model, features, labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eac7b1",
   "metadata": {},
   "source": [
    "Take a look at the decision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "197cc4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×67 adjoint(::Matrix{Float64}) with eltype Float64:\n",
       " 0.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  …  0.0  1.0  0.0  1.0  0.0  1.0  0.0\n",
       " 1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0     1.0  0.0  1.0  0.0  1.0  0.0  1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_pred = predict_proba(model, Matrix(test)[:, 1:60]);\n",
    "DT_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6a092",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Convert probability score to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3aee15bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_act  = Bool[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "label_pred = Bool[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "y_test = Bool.(test.class)\n",
    "y_DT_pred = DecisionTree.predict(model, Matrix(test)[:, 1:60]);\n",
    "\n",
    "println(\"label_act  = \", y_test)\n",
    "println(\"label_pred = \", y_DT_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b3384",
   "metadata": {},
   "source": [
    "Now let's look at the model's confusion matrix along with the previously mentioned metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c9f6ae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix of this model is [29 6; 6 26]\n",
      "The precision of this model is 0.8125\n",
      "The accuracy of this model is 0.8208955223880597\n",
      "The sensitivity of this model is 0.8125\n",
      "The specificity of this model is 0.8285714285714286\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_metrics(y_test, y_DT_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bc7f1",
   "metadata": {},
   "source": [
    "## Algorithm with the highest performance measure\n",
    "\n",
    "Let's compare some metrics of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8da324a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metrics (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"Linear Regression\", \"Logistic Regression\", \"SVM\", \"kNN\", \"Decision Tree\"]\n",
    "preds = [y_LinR_pred, y_LogR_pred, y_SVM_pred, y_kNN_pred, y_DT_pred]\n",
    "y_test = Bool.(test.class)\n",
    "n = size(models)[1]\n",
    "\n",
    "function metrics()\n",
    "    \n",
    "    for i in 1:n\n",
    "        println(\"The Precision of the \", models[i], \" model is \", EvalMetrics.precision(y_test, preds[i]))\n",
    "    end\n",
    "    \n",
    "    println(\"\")\n",
    "    \n",
    "    for i in 1:n\n",
    "        println(\"The Accuracy of the \", models[i], \" model is \", EvalMetrics.accuracy(y_test, preds[i]))\n",
    "    end\n",
    "    \n",
    "    println(\"\")\n",
    "    \n",
    "        for i in 1:n\n",
    "        println(\"The Sensitivity of the \", models[i], \" model is \", EvalMetrics.sensitivity(y_test, preds[i]))\n",
    "    end\n",
    "    \n",
    "    println(\"\")\n",
    "    \n",
    "        for i in 1:n\n",
    "        println(\"The Specificity of the \", models[i], \" model is \", EvalMetrics.specificity(y_test, preds[i]))\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8552b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Precision of the Linear Regression model is 0.8928571428571429\n",
      "The Precision of the Logistic Regression model is 0.8275862068965517\n",
      "The Precision of the SVM model is 0.574468085106383\n",
      "The Precision of the kNN model is 0.8484848484848485\n",
      "The Precision of the Decision Tree model is 0.8125\n",
      "\n",
      "The Accuracy of the Linear Regression model is 0.8507462686567164\n",
      "The Accuracy of the Logistic Regression model is 0.8059701492537313\n",
      "The Accuracy of the SVM model is 0.6268656716417911\n",
      "The Accuracy of the kNN model is 0.8656716417910447\n",
      "The Accuracy of the Decision Tree model is 0.8208955223880597\n",
      "\n",
      "The Sensitivity of the Linear Regression model is 0.78125\n",
      "The Sensitivity of the Logistic Regression model is 0.75\n",
      "The Sensitivity of the SVM model is 0.84375\n",
      "The Sensitivity of the kNN model is 0.875\n",
      "The Sensitivity of the Decision Tree model is 0.8125\n",
      "\n",
      "The Specificity of the Linear Regression model is 0.9142857142857143\n",
      "The Specificity of the Logistic Regression model is 0.8571428571428571\n",
      "The Specificity of the SVM model is 0.42857142857142855\n",
      "The Specificity of the kNN model is 0.8571428571428571\n",
      "The Specificity of the Decision Tree model is 0.8285714285714286\n"
     ]
    }
   ],
   "source": [
    "metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22862bf0",
   "metadata": {},
   "source": [
    "In this classification problem, a true negative does not represent any risk for a person, while a false negative implies the possible loss of a person's life or the loss of some part of their body, we must avoid this situation. Therefore, the model to choose must have a high sensitivity, instead of a high specificity. This is the situation that interests us when our goal is to avoid false negatives at all costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e179f",
   "metadata": {},
   "source": [
    "We can see that the models with the highest sensitivity are the kNN model and the SVM model, with 88% and 84% respectivly. Nevertheless, the precision of the kNN model is approximately 85% and the precision of the SVM model is 57%, so the kNN model is closer to the result of a prediction of the true value than the SVM model, also the accuracy of the kNN model is approximately 87% and the accuracy of the SVM model is 63%, so the kNN model has a larger percentage of correct predictions compared to the total than the SVM model. In conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7465cc0",
   "metadata": {},
   "source": [
    "#### for this problem, kNN is the best model of all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
